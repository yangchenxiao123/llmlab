{"cells":[{"cell_type":"markdown","metadata":{},"source":["## 5.4  Optional: text to video with T2V\n","We take a text-to-video model for example.\n","Use the pre-downloaded model weights on `/share/lab5/t2v`, or make sure you have downloaded the weights of it: "]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#!export HF_ENDPOINT=https://hf-mirror.com\n","#!huggingface-cli download --resume-download damo-vilab/text-to-video-ms-1.7b  --local-dir your_path_of_t2v"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Install the requirements, and you should RESTART the kernel after completing the installation.\n","# !pip install opencv-python\n","# !apt-get install libgl1 -y"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6accbd0fe18145da9e21d7e488773344","version_major":2,"version_minor":0},"text/plain":["Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","from diffusers import DiffusionPipeline\n","from diffusers.utils import export_to_video\n","\n","pipe = DiffusionPipeline.from_pretrained(\"/share/lab5/t2v\", torch_dtype=torch.float16, variant=\"fp16\")\n","pipe = pipe.to(\"cuda\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"836e4cb05c174aa1bf5286101c38d098","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/40 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'/scratch2/darth_video.mp4'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["prompt = \"Darth Vader riding a electric bike in the forest.\\n\"\n","video_frames_list = pipe(prompt,num_inference_steps=40, num_frames=100).frames\n","output_video_path = \"/scratch2/darth_video.mp4\"\n","video_path = export_to_video(video_frames=video_frames_list[0], output_video_path=output_video_path, fps=10)\n","video_path"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"754e56e8bbdf41d988b7293fa0b47ce0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/40 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'/scratch2/mickey_video.mp4'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["prompt = \"A happy mickey mouse dancing on a tower.\\n\"\n","video_frames_list = pipe(prompt,num_inference_steps=40, num_frames=100).frames\n","output_video_path = \"/scratch2/mickey_video.mp4\"\n","video_path = export_to_video(video_frames=video_frames_list[0], output_video_path=output_video_path, fps=10)\n","video_path"]},{"cell_type":"markdown","metadata":{},"source":["The above code will display the save path of the output video, and the current encoding format can be played with **VLC player**. You can download the video and view it using VLC media player. Some other media players may not view it normally.\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#### Your Task ####\n","# feel free to play with the model, and share any interesting findings.  But you do not have to submit anything for this task."]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
